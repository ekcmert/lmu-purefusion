{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f02b48b",
   "metadata": {},
   "source": [
    "# Data Load "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61919175",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "import warnings\n",
    "# -------------------------------\n",
    "# 0. Import required libraries\n",
    "# -------------------------------\n",
    "# For scaling and metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# For ARIMA and SARIMAX\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "# For Prophet\n",
    "from prophet import Prophet\n",
    "\n",
    "# For tree-based models\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "# For visualization\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ab5d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"c1_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2dbb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_order = ['Morning', 'Afternoon', 'Evening', 'Night']\n",
    "\n",
    "# Convert the column\n",
    "df['time_of_day'] = pd.Categorical(df['time_of_day'], categories=time_order, ordered=True)\n",
    "df['plant_name'] = df['plant_name'].astype('category')\n",
    "df['effectivedate'] = pd.to_datetime(df['effectivedate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e051945",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d9225a",
   "metadata": {},
   "source": [
    "Case 1: Provider 1 & Provider 2 + Supplement Forecast Data = Last FC\n",
    "- Available Plants: A, B, C, D, E, F, G, H, J, K\n",
    "\n",
    "Case 2: Provider 1 & Provider 2 + Supplement Forecast Data + Meteo Data = Last FC\n",
    "- Available Plants: A, B, C, D, E, F, G, H, J, K\n",
    "\n",
    "Case 3v1: Provider 1 & Provider 2 + Meteo Data = Dayahead FC\n",
    "- Available Plants: A, B, C, D, E, F, G, H, J, K\n",
    "\n",
    "Case 3v2: Provider 1 & Provider 2 = Dayahead FC\n",
    "- Available Plants: A, B, C, D, E, F, G, H, J, K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cc46cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if df exists before creating subsets\n",
    "if 'df' in locals() and isinstance(df, pd.DataFrame) and not df.empty:\n",
    "    df_c1 = df[['effectivedate', 'plant_name', 'production', 'capacity','year',\n",
    "           'month', 'day', 'day_of_week', 'hour', 'hour_sin', 'hour_cos',\n",
    "           'day_of_week_sin', 'day_of_week_cos', 'month_sin', 'month_cos',\n",
    "           'provider1_fc0', 'provider1_fc1200', 'provider1_fc40', 'provider1_fc55',\n",
    "           'provider1_fc60', 'provider1_fc75', 'provider2_fc0', 'provider2_fc1200',\n",
    "           'provider2_fc40', 'provider2_fc55', 'provider2_fc60', 'provider2_fc75',\n",
    "           'provider1_ramp', 'provider1_speed_fc1200_to_fc75',\n",
    "           'provider1_speed_fc75_to_fc60', 'provider1_speed_fc60_to_fc55',\n",
    "           'provider1_speed_fc55_to_fc40', 'provider1_speed_fc40_to_fc0',\n",
    "           'provider1_volatility', 'provider1_std_fc', 'provider1_mean_fc',\n",
    "           'provider2_ramp', 'provider2_speed_fc1200_to_fc75',\n",
    "           'provider2_speed_fc75_to_fc60', 'provider2_speed_fc60_to_fc55',\n",
    "           'provider2_speed_fc55_to_fc40', 'provider2_speed_fc40_to_fc0',\n",
    "           'provider2_volatility', 'provider2_std_fc', 'provider2_mean_fc',\n",
    "           'season', 'is_weekend', 'time_of_day', 'week_of_year']].copy()\n",
    "\n",
    "    df_c2 = df.copy() # Contains ALL original columns\n",
    "\n",
    "    df_c3 = df[['effectivedate', 'plant_name', 'production', 'capacity',\n",
    "           'temperature_2m', 'relative_humidity_2m', 'dew_point_2m',\n",
    "           'apparent_temperature', 'precipitation', 'rain', 'snowfall',\n",
    "           'snow_depth', 'weather_code_x', 'pressure_msl', 'surface_pressure',\n",
    "           'cloud_cover', 'cloud_cover_low', 'cloud_cover_mid', 'cloud_cover_high',\n",
    "           'et0_fao_evapotranspiration_x', 'vapour_pressure_deficit',\n",
    "           'wind_speed_10m', 'wind_direction_10m', 'wind_gusts_10m',\n",
    "           'et0_fao_evapotranspiration_y', 'temperature_2m_max',\n",
    "           'temperature_2m_min', 'apparent_temperature_max',\n",
    "           'apparent_temperature_min', 'daylight_duration', 'sunshine_duration',\n",
    "           'precipitation_sum', 'rain_sum', 'snowfall_sum', 'precipitation_hours',\n",
    "           'wind_speed_10m_max', 'wind_gusts_10m_max',\n",
    "           'wind_direction_10m_dominant', 'shortwave_radiation_sum', 'year',\n",
    "           'month', 'day', 'day_of_week', 'hour', 'hour_sin', 'hour_cos',\n",
    "           'day_of_week_sin', 'day_of_week_cos', 'month_sin', 'month_cos',\n",
    "            'provider1_fc1200', 'provider2_fc1200', # Only fc1200 from providers\n",
    "           'season', 'is_weekend', 'time_of_day', 'week_of_year',\n",
    "           'weather_category_x', 'wind_u', 'wind_v', 'wind_gust_u', 'wind_gust_v',\n",
    "           'wind_speed_squared', 'wind_speed_cubed', 'is_raining', 'is_snowing']].copy()\n",
    "\n",
    "    df_c4 = df[['effectivedate', 'plant_name', 'production', 'capacity','year',\n",
    "           'month', 'day', 'day_of_week', 'hour', 'hour_sin', 'hour_cos',\n",
    "           'day_of_week_sin', 'day_of_week_cos', 'month_sin', 'month_cos',\n",
    "           'provider1_fc1200', 'provider2_fc1200', # Only fc1200 from providers\n",
    "           'season', 'is_weekend', 'time_of_day', 'week_of_year']].copy()\n",
    "else:\n",
    "    print(\"Warning: DataFrame 'df' not found or empty. Please load your data first.\")\n",
    "    # Create empty placeholders if needed for the script to run without error\n",
    "    df_c1, df_c2, df_c3, df_c4 = pd.DataFrame(), pd.DataFrame(), pd.DataFrame(), pd.DataFrame()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f47fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cases = {\n",
    "    \"case_1\":df_c1,\n",
    "    \"case_2\":df_c2,\n",
    "    \"case_3\":df_c3,\n",
    "    \"case_4\":df_c4,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b24b42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed646e0",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b2530c",
   "metadata": {},
   "source": [
    "This pipeline is suitable for testing \"plant level\" performances of the available models. It provides several customization options for the rolling window training methodology. Capacity factor forecasting can be adapted to this pipeline if \"production to capacity factor\" and \"capacity factor to production\" conversions handled externally. Capacity factor prediction with the whole data (including multiple plants) can be used as a POC for \"regional power generation models\" where power plants within the same regions who has similar production patterns can be forecasted together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef945540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 1. Helper functions for data preparation\n",
    "# -------------------------------\n",
    "def prepare_features_for_regression(train_df, test_df, target_column, date_column):\n",
    "    \"\"\"\n",
    "    Prepare training and test features:\n",
    "      - Drop target and date columns.\n",
    "      - One-hot encode categorical features.\n",
    "      - Align train and test columns.\n",
    "    \"\"\"\n",
    "    X_train = train_df.drop(columns=[target_column, date_column])\n",
    "    X_test = test_df.drop(columns=[target_column, date_column])\n",
    "    \n",
    "    # One-hot encoding for categorical columns\n",
    "    X_train = pd.get_dummies(X_train, drop_first=True)\n",
    "    X_test = pd.get_dummies(X_test, drop_first=True)\n",
    "    \n",
    "    # Align columns between train and test (fill missing with 0)\n",
    "    X_train, X_test = X_train.align(X_test, join='left', axis=1, fill_value=0)\n",
    "    \n",
    "    y_train = train_df[target_column].values\n",
    "    y_test = test_df[target_column].values\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "def prepare_regressor_data_for_prophet(df, regressor_columns):\n",
    "    \"\"\"\n",
    "    For Prophet (with regressors), convert categorical features to numeric codes.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    for col in regressor_columns:\n",
    "        if isinstance(df[col].dtype, pd.CategoricalDtype) or df[col].dtype == object:\n",
    "            df[col] = df[col].astype('category').cat.codes\n",
    "    return df\n",
    "\n",
    "def get_categorical_columns(df, threshold=20):\n",
    "    \"\"\"\n",
    "    Identify categorical columns in a DataFrame.\n",
    "    This function returns columns that are either of object or categorical dtype,\n",
    "    or numeric columns with fewer than `threshold` unique values.\n",
    "    \"\"\"\n",
    "    cat_cols = []\n",
    "    for col in df.columns:\n",
    "        # If already object or categorical, add it.\n",
    "        if df[col].dtype == 'object' or isinstance(df[col].dtype, pd.CategoricalDtype):\n",
    "            cat_cols.append(col)\n",
    "        # Otherwise, if numeric but with very few unique values, consider it categorical.\n",
    "        elif np.issubdtype(df[col].dtype, np.number):\n",
    "            if df[col].nunique() < threshold:\n",
    "                cat_cols.append(col)\n",
    "    return cat_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ad9a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -------------------------------\n",
    "# 2. Model training functions\n",
    "# -------------------------------\n",
    "def train_arima(y_train, forecast_steps):\n",
    "    \"\"\"\n",
    "    Train a simple ARIMA model on the target series and forecast for the specified number of steps.\n",
    "    Here we choose an order of (1,1,1) for demonstration.\n",
    "    \"\"\"\n",
    "    model = ARIMA(y_train, order=(2,1,2))\n",
    "    model_fit = model.fit()\n",
    "    forecast = model_fit.forecast(steps=forecast_steps)\n",
    "    return forecast  # Removed .values as forecast is already a numpy array\n",
    "\n",
    "def train_sarima(y_train, forecast_steps):\n",
    "    \"\"\"\n",
    "    SARIMA with order=(2,1,2) and seasonal_order=(1,1,1,24)\n",
    "    for hourly data\n",
    "    \"\"\"\n",
    "    model = SARIMAX(\n",
    "        y_train, \n",
    "        order=(2,1,2), \n",
    "        seasonal_order=(1,1,1,24),         \n",
    "        enforce_stationarity=False,\n",
    "        enforce_invertibility=False\n",
    "    )\n",
    "    model_fit = model.fit(disp=False, maxiter=500, method='powell')\n",
    "    forecast = model_fit.forecast(steps=forecast_steps)\n",
    "    return forecast\n",
    "\n",
    "\n",
    "def train_prophet(train_df, test_df, date_column, target_column):\n",
    "    \"\"\"\n",
    "    Train a Prophet model using only the target series.\n",
    "    \"\"\"\n",
    "    df_train = train_df[[date_column, target_column]].rename(columns={date_column: 'ds', target_column: 'y'})\n",
    "    model = Prophet(\n",
    "        changepoint_prior_scale=0.1,    # Lower value for smoother trend\n",
    "        seasonality_prior_scale=10.0,   # Slightly lower to prevent overfitting seasonality\n",
    "        changepoint_range=0.9,\n",
    "        n_changepoints=50,             # More potential changepoints for complex patterns\n",
    "        yearly_seasonality=False,       # Set to True if data spans multiple years\n",
    "        weekly_seasonality=True,\n",
    "        daily_seasonality=True\n",
    "    )\n",
    "    model.add_seasonality(name='2H', period=1/12, fourier_order=12)\n",
    "    model.add_seasonality(name='4H', period=1/6, fourier_order=12)\n",
    "    model.add_seasonality(name='8H', period=1/3, fourier_order=12)\n",
    "    model.fit(df_train)\n",
    "    df_test = test_df[[date_column]].rename(columns={date_column: 'ds'})\n",
    "    forecast = model.predict(df_test)\n",
    "    return forecast['yhat'].values\n",
    "\n",
    "def train_prophet_with_regressors(train_df, test_df, date_column, target_column, regressor_columns):\n",
    "    \"\"\"\n",
    "    Train a Prophet model including extra regressors.\n",
    "    The function first prepares the data by renaming the date and target columns.\n",
    "    For any regressor that is categorical, we convert it to numeric codes.\n",
    "    \"\"\"\n",
    "    # Prepare data for Prophet\n",
    "    df_train = train_df[[date_column, target_column] + regressor_columns].rename(\n",
    "        columns={date_column: 'ds', target_column: 'y'}\n",
    "    )\n",
    "    df_train = prepare_regressor_data_for_prophet(df_train, regressor_columns)\n",
    "    model = Prophet(\n",
    "        changepoint_prior_scale=0.1,    # Lower value for smoother trend\n",
    "        seasonality_prior_scale=10.0,   # Slightly lower to prevent overfitting seasonality\n",
    "        changepoint_range=0.9,\n",
    "        n_changepoints=50,             # More potential changepoints for complex patterns\n",
    "        yearly_seasonality=False,       # Set to True if data spans multiple years\n",
    "        weekly_seasonality=True,\n",
    "        daily_seasonality=True\n",
    "    )\n",
    "    model.add_seasonality(name='2H', period=1/12, fourier_order=12)\n",
    "    model.add_seasonality(name='4H', period=1/6, fourier_order=12)\n",
    "    model.add_seasonality(name='8H', period=1/3, fourier_order=12)\n",
    "    for col in regressor_columns:\n",
    "        model.add_regressor(col)\n",
    "    model.fit(df_train)\n",
    "    \n",
    "    df_test = test_df[[date_column] + regressor_columns].rename(columns={date_column: 'ds'})\n",
    "    df_test = prepare_regressor_data_for_prophet(df_test, regressor_columns)\n",
    "    forecast = model.predict(df_test)\n",
    "    return forecast['yhat'].values\n",
    "\n",
    "def train_lgbm(X_train, y_train, X_test):\n",
    "\n",
    "    model = LGBMRegressor(\n",
    "        random_state=42,\n",
    "        n_estimators=100,\n",
    "        learning_rate=0.1,\n",
    "        num_leaves=61,\n",
    "        max_depth=8,\n",
    "        boosting_type='gbdt'\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    return preds\n",
    "\n",
    "def train_xgboost(X_train, y_train, X_test):\n",
    "    model = XGBRegressor(\n",
    "        random_state=42,\n",
    "        n_estimators=50,      # More boosting rounds\n",
    "        learning_rate=0.1,    # Lower learning rate\n",
    "        max_depth=7,           # Allow deeper trees for capturing complex interactions\n",
    "        subsample=0.8,         # Use 80% of data for each tree to reduce overfitting\n",
    "        colsample_bytree=0.8,\n",
    "        verbosity=0\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    return model.predict(X_test)\n",
    "\n",
    "def train_catboost_df(train_df, y_train, test_df, cat_features):\n",
    "    \"\"\"\n",
    "    Train CatBoost using DataFrame inputs and leverage its native handling of categorical features.\n",
    "    The categorical features are cast to string to avoid type errors.\n",
    "    \"\"\"\n",
    "    # Convert the categorical features to string\n",
    "    train_df = train_df.copy()\n",
    "    test_df = test_df.copy()\n",
    "    for col in cat_features:\n",
    "        train_df[col] = train_df[col].astype(str)\n",
    "        test_df[col] = test_df[col].astype(str)\n",
    "    \n",
    "    model = CatBoostRegressor(\n",
    "        iterations=50,\n",
    "        learning_rate=0.1,\n",
    "        depth=8,\n",
    "        random_seed=42,\n",
    "        verbose=0\n",
    "    )\n",
    "    model.fit(train_df, y_train, cat_features=cat_features)\n",
    "    return model.predict(test_df)\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# 3. Rolling window training pipeline\n",
    "# -------------------------------\n",
    "def rolling_window_forecasting(df, target_column, date_column, models_to_run,\n",
    "                               train_window_days, test_window_days, rows_per_day,\n",
    "                               optimization_metric='rmse', max_iterations=None,\n",
    "                               max_clip=100, min_clip=0, ensemble_weights=None, starter=0):\n",
    "    \"\"\"\n",
    "    Perform rolling-window forecasting.\n",
    "    \n",
    "    Parameters:\n",
    "      - df: Original DataFrame (must include date and target columns).\n",
    "      - target_column: Name of the target variable.\n",
    "      - date_column: Name of the date/time column.\n",
    "      - models_to_run: List of model names to run. (Allowed: 'arima', 'sarima', 'prophet', 'prophet_reg',\n",
    "                        'lgbm', 'xgboost', 'catboost', and the baselines: 'baseline_last', 'baseline_mean7', 'baseline_yesterday',\n",
    "                        and 'weighted_ensemble')\n",
    "      - train_window_days: Number of days to use for training.\n",
    "      - test_window_days: Number of days to use for testing.\n",
    "      - rows_per_day: Number of rows per day (e.g. 96 for 15-minute intervals or 24 for hourly).\n",
    "      - optimization_metric: (Not used inside the loop but can be used later for tuning.)\n",
    "      - max_iterations: Maximum number of rolling window iterations to perform (default None means no limit).\n",
    "      - max_clip: Maximum value to clip predictions.\n",
    "      - min_clip: Minimum value to clip predictions.\n",
    "      - ensemble_weights: Dictionary of weights for the ensemble forecast, e.g.\n",
    "            {'prophet_reg': 0.25, 'lgbm': 0.25, 'catboost': 0.25, 'xgboost': 0.25}.\n",
    "            If None, equal weights will be used.\n",
    "      \n",
    "    Returns:\n",
    "      - predictions_df: DataFrame with test rows (with re-assigned, continuous test dates)\n",
    "        plus a column per model with its predictions (all clipped between min_clip and max_clip)\n",
    "        including the three baselines and the weighted ensemble.\n",
    "    \"\"\"\n",
    "    # Ensure the date column is datetime and sort by date\n",
    "    df = df.copy()\n",
    "    cat_columns = get_categorical_columns(df.drop(columns=[target_column, date_column]), threshold=50)\n",
    "    df[date_column] = pd.to_datetime(df[date_column])\n",
    "    df.sort_values(by=date_column, inplace=True)\n",
    "    \n",
    "    predictions_list = []\n",
    "    total_rows = df.shape[0]\n",
    "    train_window = train_window_days * rows_per_day\n",
    "    test_window = test_window_days * rows_per_day\n",
    "\n",
    "    # Derive frequency string based on rows_per_day.\n",
    "    # For example, if rows_per_day = 96, then interval = 1440/96 = 15 minutes.\n",
    "    # For hourly data (rows_per_day = 24), freq_str will be \"60min\".\n",
    "    freq_str = f\"{1440 // rows_per_day}min\"\n",
    "    \n",
    "    # Determine base test date from the first available test window.\n",
    "    base_test_date = df.iloc[train_window][date_column]\n",
    "    \n",
    "    # Calculate total iterations available based on the data.\n",
    "    total_iterations_available = ((total_rows - train_window - test_window) // test_window) + 1\n",
    "    if max_iterations is not None:\n",
    "        total_iterations = min(total_iterations_available, max_iterations)\n",
    "    else:\n",
    "        total_iterations = total_iterations_available\n",
    "    \n",
    "    from tqdm.notebook import tqdm\n",
    "    pbar = tqdm(total=total_iterations, desc=\"Rolling Window Forecasting\", unit=\"window\")\n",
    "    \n",
    "    iteration_count = 0\n",
    "    start_idx = starter\n",
    "    print(start_idx)\n",
    "    while start_idx + train_window + test_window <= total_rows and (max_iterations is None or iteration_count < max_iterations):\n",
    "        # Get the current training and test windows\n",
    "        train_df = df.iloc[start_idx: start_idx + train_window].copy()\n",
    "        test_df = df.iloc[start_idx + train_window: start_idx + train_window + test_window].copy()\n",
    "        \n",
    "        # Reset the date column in the test window to be continuous\n",
    "        # new_start = base_test_date + pd.Timedelta(days=iteration_count * test_window_days)\n",
    "        # new_dates = pd.date_range(start=new_start, periods=len(test_df), freq=freq_str)\n",
    "        # test_df[date_column] = new_dates\n",
    "        \n",
    "        # Prepare features for regression models\n",
    "        X_train, y_train, X_test, y_test = prepare_features_for_regression(train_df, test_df, target_column, date_column)\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        \n",
    "        # For Prophet models, use the raw (or minimally transformed) data.\n",
    "        regressor_columns = list(train_df.columns.drop([target_column, date_column]))\n",
    "        train_df_prophet = train_df.copy()\n",
    "        test_df_prophet = test_df.copy()\n",
    "        \n",
    "        # Start with the test window DataFrame (with reset dates)\n",
    "        window_predictions = test_df.copy()\n",
    "        \n",
    "        # Loop over each model requested and add its predictions\n",
    "        for model_name in models_to_run:\n",
    "            if model_name == 'arima':\n",
    "                preds = train_arima(train_df[target_column].values, len(test_df))\n",
    "            elif model_name == 'sarima':\n",
    "                preds = train_sarima(train_df[target_column].values, len(test_df))\n",
    "            elif model_name == 'prophet':\n",
    "                preds = train_prophet(train_df, test_df, date_column, target_column)\n",
    "            elif model_name == 'prophet_reg':\n",
    "                preds = train_prophet_with_regressors(train_df_prophet, test_df_prophet, date_column, target_column, regressor_columns)\n",
    "            elif model_name == 'lgbm':\n",
    "                preds = train_lgbm(X_train_scaled, y_train, X_test_scaled)\n",
    "            elif model_name == 'xgboost':\n",
    "                preds = train_xgboost(X_train_scaled, y_train, X_test_scaled)\n",
    "            elif model_name == 'catboost':\n",
    "                # Use the raw features (no one-hot encoding) for CatBoost.\n",
    "                X_train_cat = train_df.drop(columns=[target_column, date_column])\n",
    "                X_test_cat = test_df.drop(columns=[target_column, date_column])\n",
    "                preds = train_catboost_df(X_train_cat, train_df[target_column].values, X_test_cat, cat_features=cat_columns)\n",
    "\n",
    "            # Baseline 1: Last Value (naive forecast)\n",
    "            elif model_name == 'baseline_last':\n",
    "                baseline_last = np.empty(len(test_df))\n",
    "                for i in range(len(test_df)):\n",
    "                    if i == 0:\n",
    "                        baseline_last[i] = train_df[target_column].iloc[-1]\n",
    "                    else:\n",
    "                        baseline_last[i] = test_df[target_column].iloc[i - 1]\n",
    "                preds = baseline_last\n",
    "            # Baseline 2: Mean of Last 7 Days for the Same Hour\n",
    "            elif model_name == 'baseline_mean7':\n",
    "                baseline_mean7 = np.empty(len(test_df))\n",
    "                for i in range(len(test_df)):\n",
    "                    current_timestamp = test_df[date_column].iloc[i]\n",
    "                    current_hour = current_timestamp.hour\n",
    "                    subset = train_df[(train_df[date_column] >= current_timestamp - pd.Timedelta(days=7)) &\n",
    "                                      (train_df[date_column] < current_timestamp)]\n",
    "                    subset_same_hour = subset[subset[date_column].dt.hour == current_hour]\n",
    "                    if len(subset_same_hour) > 0:\n",
    "                        baseline_mean7[i] = subset_same_hour[target_column].mean()\n",
    "                    else:\n",
    "                        subset_all = train_df[train_df[date_column].dt.hour == current_hour]\n",
    "                        if len(subset_all) > 0:\n",
    "                            baseline_mean7[i] = subset_all[target_column].mean()\n",
    "                        else:\n",
    "                            baseline_mean7[i] = train_df[target_column].mean()\n",
    "                preds = baseline_mean7\n",
    "            # Baseline 3: Yesterday's Value (seasonal naive)\n",
    "            elif model_name == 'baseline_yesterday':\n",
    "                baseline_yesterday = np.empty(len(test_df))\n",
    "                for i in range(len(test_df)):\n",
    "                    if i < rows_per_day:\n",
    "                        baseline_yesterday[i] = train_df[target_column].iloc[-rows_per_day + i]\n",
    "                    else:\n",
    "                        baseline_yesterday[i] = test_df[target_column].iloc[i - rows_per_day]\n",
    "                preds = baseline_yesterday\n",
    "            # Weighted Ensemble of 'prophet_reg', 'lgbm', 'catboost', and 'xgboost'\n",
    "            elif model_name == 'weighted_ensemble':\n",
    "                try:\n",
    "                    # If ensemble_weights not provided, use equal weights\n",
    "                    if ensemble_weights is None:\n",
    "                        weights = {'prophet_reg': 1, 'lgbm': 1, 'catboost': 1, 'xgboost': 1}\n",
    "                    else:\n",
    "                        weights = ensemble_weights\n",
    "                    w1 = weights.get('prophet_reg', 1)\n",
    "                    w2 = weights.get('lgbm', 1)\n",
    "                    w3 = weights.get('catboost', 1)\n",
    "                    w4 = weights.get('xgboost', 1)\n",
    "                    sum_weights = w1 + w2 + w3 + w4\n",
    "                    ensemble_preds = (w1 * window_predictions['prophet_reg'] +\n",
    "                                      w2 * window_predictions['lgbm'] +\n",
    "                                      w3 * window_predictions['catboost'] +\n",
    "                                      w4 * window_predictions['xgboost']) / sum_weights\n",
    "                    preds = ensemble_preds\n",
    "                except KeyError:\n",
    "                    print(\"Warning: Not all required models for weighted ensemble found. Skipping weighted ensemble.\")\n",
    "                    continue\n",
    "            else:\n",
    "                print(f\"Warning: Model {model_name} not recognized. Skipping.\")\n",
    "                continue\n",
    "            \n",
    "            # Clip predictions between min_clip and max_clip\n",
    "            window_predictions[model_name] = np.clip(preds, min_clip, max_clip)\n",
    "        \n",
    "        predictions_list.append(window_predictions)\n",
    "        start_idx += test_window  # Slide the window forward\n",
    "        iteration_count += 1\n",
    "        pbar.update(1)\n",
    "    \n",
    "    pbar.close()\n",
    "    predictions_df = pd.concat(predictions_list, axis=0)\n",
    "    return predictions_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fbe094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 4. Evaluation and Visualization Pipeline\n",
    "# -------------------------------\n",
    "def evaluate_and_visualize(prediction_df, date_column, true_column, prediction_columns,\n",
    "                           barplot_filename=\"barplot.html\", lineplot_filename=\"lineplot.html\"):\n",
    "    \"\"\"\n",
    "    Given a DataFrame that includes:\n",
    "      - a date column,\n",
    "      - a true value column, and\n",
    "      - one or more prediction columns (each named for the model),\n",
    "    this function computes performance metrics and creates two Plotly figures:\n",
    "      1) A single bar plot showing MAE, RMSE, MAPE, MAAPE (arctan MAPE), sMAPE, and MASE.\n",
    "      2) A line plot showing true values and all predictions over time.\n",
    "    \n",
    "    The plots are saved as HTML files with the given filenames.\n",
    "    \n",
    "    Returns:\n",
    "      - metrics_df: a DataFrame summarizing the metrics per model.\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    metrics_dict = {}\n",
    "    for col in prediction_columns:\n",
    "        y_true = prediction_df[true_column].values\n",
    "        y_pred = prediction_df[col].values\n",
    "        \n",
    "        mae = mean_absolute_error(y_true, y_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "        \n",
    "        # MAPE and MAAPE: Avoid division by zero by only computing on non-zero true values.\n",
    "        nonzero_mask = y_true != 0\n",
    "        if np.any(nonzero_mask):\n",
    "            mape = np.mean(np.abs((y_true[nonzero_mask] - y_pred[nonzero_mask]) / y_true[nonzero_mask])) * 100\n",
    "            maape = np.mean(np.arctan(np.abs((y_true[nonzero_mask] - y_pred[nonzero_mask]) / y_true[nonzero_mask])))\n",
    "        else:\n",
    "            mape = np.nan\n",
    "            maape = np.nan\n",
    "\n",
    "        # sMAPE: Avoid division by zero in the denominator.\n",
    "        denominator = np.abs(y_true) + np.abs(y_pred)\n",
    "        nonzero_denom_mask = denominator != 0\n",
    "        if np.any(nonzero_denom_mask):\n",
    "            smape = np.mean(2 * np.abs(y_pred[nonzero_denom_mask] - y_true[nonzero_denom_mask]) / denominator[nonzero_denom_mask]) * 100\n",
    "        else:\n",
    "            smape = np.nan\n",
    "\n",
    "        # MASE: Use the naive forecast (lag 1) errors; if their mean is zero, set MASE to np.nan.\n",
    "        naive_errors = np.abs(np.diff(y_true))\n",
    "        mean_naive_error = np.mean(naive_errors) if np.mean(naive_errors) != 0 else np.nan\n",
    "        mase = mae / mean_naive_error if mean_naive_error != 0 else np.nan\n",
    "        \n",
    "        metrics_dict[col] = {\n",
    "            'MAE': mae,\n",
    "            'RMSE': rmse,\n",
    "            'MAPE': mape,\n",
    "            'MAAPE': maape,\n",
    "            'sMAPE': smape,\n",
    "            'MASE': mase\n",
    "        }\n",
    "    \n",
    "    metrics_df = pd.DataFrame(metrics_dict).T.reset_index().rename(columns={'index': 'Model'})\n",
    "    \n",
    "    # Create a single grouped bar plot with all metrics.\n",
    "    fig_bar = go.Figure()\n",
    "    fig_bar.add_trace(go.Bar(x=metrics_df['Model'], y=metrics_df['MAE'], name='MAE'))\n",
    "    fig_bar.add_trace(go.Bar(x=metrics_df['Model'], y=metrics_df['RMSE'], name='RMSE'))\n",
    "    fig_bar.add_trace(go.Bar(x=metrics_df['Model'], y=metrics_df['MAPE'], name='MAPE'))\n",
    "    fig_bar.add_trace(go.Bar(x=metrics_df['Model'], y=metrics_df['MAAPE'], name='MAAPE'))\n",
    "    fig_bar.add_trace(go.Bar(x=metrics_df['Model'], y=metrics_df['sMAPE'], name='sMAPE'))\n",
    "    fig_bar.add_trace(go.Bar(x=metrics_df['Model'], y=metrics_df['MASE'], name='MASE'))\n",
    "    \n",
    "    fig_bar.update_layout(title=\"Performance Metrics per Model\",\n",
    "                          barmode='group',\n",
    "                          xaxis_title=\"Model\",\n",
    "                          yaxis_title=\"Metric Value\")\n",
    "    fig_bar.write_html(barplot_filename)\n",
    "    fig_bar.show()\n",
    "    \n",
    "    # Create a line plot for true vs. predicted values over time\n",
    "    fig_line = go.Figure()\n",
    "    fig_line.add_trace(go.Scatter(x=prediction_df[date_column], y=prediction_df[true_column],\n",
    "                                  mode='lines', name='True', line=dict(width=2)))\n",
    "    for col in prediction_columns:\n",
    "        fig_line.add_trace(go.Scatter(x=prediction_df[date_column], y=prediction_df[col],\n",
    "                                      mode='lines', name=col, line=dict(width=2)))\n",
    "    fig_line.update_layout(title=\"True vs. Predicted Values\", xaxis_title=date_column, yaxis_title=true_column)\n",
    "    fig_line.write_html(lineplot_filename)\n",
    "    fig_line.show()\n",
    "    \n",
    "    return metrics_df\n",
    "\n",
    "# -------------------------------\n",
    "# 5. Main forecasting pipeline function\n",
    "# -------------------------------\n",
    "def run_forecasting_pipeline(df, target_column, date_column, comparison_columns, models_to_run,\n",
    "                             optimization_metric='rmse', train_window_days=90,\n",
    "                             test_window_days=7, rows_per_day=24,max_iterations=3, max_clip=100, start_idx=0,\n",
    "                             barplot_filename=\"barplot.html\", lineplot_filename=\"lineplot.html\"):\n",
    "    \"\"\"\n",
    "    End-to-end pipeline:\n",
    "      - Prepares the data,\n",
    "      - Runs rolling-window training for the requested models,\n",
    "      - Merges predictions with the original features (for test windows),\n",
    "      - Evaluates and visualizes performance.\n",
    "    \n",
    "    Returns:\n",
    "      - predictions_df: DataFrame with test rows and one column per model prediction.\n",
    "      - metrics_df: Summary of evaluation metrics per model.\n",
    "    \"\"\"\n",
    "    predictions_df = rolling_window_forecasting(\n",
    "        df, target_column, date_column, models_to_run,\n",
    "        train_window_days, test_window_days, rows_per_day,\n",
    "        optimization_metric, max_iterations, max_clip, starter=start_idx\n",
    "    )\n",
    "    candidates = models_to_run + comparison_columns\n",
    "    # Evaluate using the provided true target values and model prediction columns.\n",
    "    metrics_df = evaluate_and_visualize(\n",
    "        predictions_df, date_column, target_column, candidates,\n",
    "        barplot_filename, lineplot_filename\n",
    "    )\n",
    "    \n",
    "    return predictions_df, metrics_df\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# 6. aggregate forecasting pipeline function\n",
    "# -------------------------------\n",
    "def run_aggregate_pipeline(df, target_column, date_column, comparison_columns, models_to_run,\n",
    "                             optimization_metric='rmse', train_window_days=90,\n",
    "                             test_window_days=7, rows_per_day=24,max_iterations=3, max_clip=100, start_idx=0,\n",
    "                             barplot_filename=\"barplot.html\", lineplot_filename=\"lineplot.html\"):\n",
    "    \"\"\"\n",
    "    End-to-end pipeline:\n",
    "      - Prepares the data,\n",
    "      - Runs rolling-window training for the requested models,\n",
    "      - Merges predictions with the original features (for test windows),\n",
    "      - Evaluates and visualizes performance.\n",
    "    \n",
    "    Returns:\n",
    "      - predictions_df: DataFrame with test rows and one column per model prediction.\n",
    "      - metrics_df: Summary of evaluation metrics per model.\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "    for plant in df.plant_name.unique():\n",
    "        df_ex = df.copy()\n",
    "        df_ex = df_ex[df_ex.plant_name == plant]\n",
    "    \n",
    "        predictions_df = rolling_window_forecasting(\n",
    "            df_ex, target_column, date_column, models_to_run,\n",
    "            train_window_days, test_window_days, rows_per_day,\n",
    "            optimization_metric, max_iterations, max_clip, starter=start_idx\n",
    "        )\n",
    "        predictions.append(predictions_df)\n",
    "    \n",
    "    all_cols = models_to_run + comparison_columns + [date_column] + [target_column]\n",
    "    df_pred_all = pd.concat(predictions)[all_cols]\n",
    "    df_pred_agg = df_pred_all.groupby(date_column, as_index=False).sum()\n",
    "    \n",
    "    \n",
    "    candidates = models_to_run + comparison_columns\n",
    "    # Evaluate using the provided true target values and model prediction columns.\n",
    "    metrics_df = evaluate_and_visualize(\n",
    "        df_pred_agg, date_column, target_column, candidates,\n",
    "        barplot_filename, lineplot_filename\n",
    "    )\n",
    "    \n",
    "    return predictions_df, metrics_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932a6525",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_case = df_c4.copy()\n",
    "df_case = df_case[df_case.plant_name == 1].drop(columns=[\"plant_name\", \"capacity\"])\n",
    "\n",
    "# Assume target is \"production\" and date is \"effectivedate\"\n",
    "\n",
    "# Define which models to run – choose any subset of:\n",
    "# 'arima', 'prophet', 'prophet_reg', 'lgbm', 'xgboost', 'catboost'\n",
    "models_to_run = ['baseline_yesterday', 'baseline_mean7', 'baseline_last','arima', \"sarima\", 'prophet', 'prophet_reg', 'lgbm', 'xgboost', 'catboost','weighted_ensemble']\n",
    "models_to_run = [\"lgbm\"]\n",
    "# Run the forecasting pipeline.\n",
    "predictions, metrics = run_forecasting_pipeline(\n",
    "    df=df_case,\n",
    "    target_column=\"production\",\n",
    "    date_column=\"effectivedate\",\n",
    "    comparison_columns = [\"provider1_fc1200\",\"provider2_fc1200\"],\n",
    "    models_to_run=models_to_run,\n",
    "    optimization_metric='mae',   # or 'mae'\n",
    "    train_window_days=30,\n",
    "    test_window_days=7,\n",
    "    rows_per_day=24,               \n",
    "    max_iterations = 2,\n",
    "    barplot_filename=\"forecast_barplota.html\",\n",
    "    lineplot_filename=\"forecast_lineplot.html\",\n",
    "    max_clip=23.3,\n",
    "    start_idx=20000\n",
    ")\n",
    "\n",
    "# Optionally, save the predictions DataFrame\n",
    "predictions.to_csv(\"forecast_predictions.csv\", index=False)\n",
    "print(\"Forecasting pipeline completed. Metrics:\")\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c644120b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38294744",
   "metadata": {},
   "source": [
    "# Case Runs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af7ff54",
   "metadata": {},
   "source": [
    "Case 1: Provider 1 & Provider 2 + Supplement Forecast Data = Last FC\n",
    "- Available Plants: A, B, C, D, E, F, G, H, J, K\n",
    "\n",
    "Case 2: Provider 1 & Provider 2 + Supplement Forecast Data + Meteo Data = Last FC\n",
    "- Available Plants: A, B, C, D, E, F, G, H, J, K\n",
    "\n",
    "Case 3v1: Provider 1 & Provider 2 + Meteo Data = Dayahead FC\n",
    "- Available Plants: A, B, C, D, E, F, G, H, J, K\n",
    "\n",
    "Case 3v2: Provider 1 & Provider 2 = Dayahead FC\n",
    "- Available Plants: A, B, C, D, E, F, G, H, J, K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cadc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_list = list(df.capacity.unique())\n",
    "cap_list.sort()\n",
    "cap_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4ad20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[df.plant_name==3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e445be7",
   "metadata": {},
   "source": [
    "For Plants: 6 (112.6), 2 (74.8), 5 (57.0), 3 (50.5) \n",
    "\n",
    "- Case 1,2,3,4 MAE\n",
    "- Case 1,2,3,4 RMSE\n",
    "- Training 180 Days\n",
    "- Test 15 Days\n",
    "- 2 Iterations with start_idx = 0\n",
    "- 2 Iterastions with start_idx = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e1543a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1810e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = 'mae'\n",
    "case_name = 'case_2'\n",
    "df_case = cases[case_name].copy()\n",
    "# df_case = df_case[(df_case.plant_name == 6) | (df_case.plant_name == 2)]\n",
    "if case_name == \"case_3\" or  case_name == \"case_4\":\n",
    "    comp_cols = [\"provider1_fc1200\",\"provider2_fc1200\"]\n",
    "else:\n",
    "    comp_cols = [\"provider1_fc0\",\"provider2_fc0\"]\n",
    "starter = 20000\n",
    "models_to_run = ['baseline_yesterday', 'baseline_mean7', 'baseline_last','arima', \"sarima\", 'prophet', \n",
    "                                 'prophet_reg', 'lgbm', 'xgboost', 'catboost','weighted_ensemble']\n",
    "\n",
    "preds = run_aggregate_pipeline(df=df_case,\n",
    "                    target_column=\"production\",\n",
    "                    date_column=\"effectivedate\",\n",
    "                    comparison_columns = comp_cols,\n",
    "                    models_to_run=models_to_run,\n",
    "                    optimization_metric=opt,   # or 'mae'\n",
    "                    train_window_days=180,\n",
    "                    test_window_days=15,\n",
    "                    rows_per_day=24,               \n",
    "                    max_iterations = 2,\n",
    "                    barplot_filename=f\"forecast_barplot_{opt}_{case_name}_idx{starter}.html\",\n",
    "                    lineplot_filename=f\"forecast_lineplot_{opt}_{case_name}_idx{starter}.html\",\n",
    "                    max_clip=150,\n",
    "                    start_idx=starter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b292b91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for case_name,case_df in cases.items():\n",
    "    if case_name == \"case_3\" or  case_name == \"case_4\":\n",
    "        comp_cols = [\"provider1_fc1200\",\"provider2_fc1200\"]\n",
    "    else:\n",
    "        comp_cols = [\"provider1_fc0\",\"provider2_fc0\"]\n",
    "    for plant in [6,2,5,3]:\n",
    "        for opt in [\"mae\",\"rmse\"]:\n",
    "            for starter in [0,20000]:\n",
    "                # Define which models to run – choose any subset of:\n",
    "                # 'arima', 'prophet', 'prophet_reg', 'lgbm', 'xgboost', 'catboost'\n",
    "                models_to_run = ['baseline_yesterday', 'baseline_mean7', 'baseline_last','arima', \"sarima\", 'prophet', \n",
    "                                 'prophet_reg', 'lgbm', 'xgboost', 'catboost','weighted_ensemble']\n",
    "#                 models_to_run = [\"lgbm\"]\n",
    "                df_ex = case_df.copy()\n",
    "                df_ex = df_ex[df_ex.plant_name == plant]\n",
    "                # Run the forecasting pipeline.\n",
    "                predictions, metrics = run_forecasting_pipeline(\n",
    "                    df=df_ex,\n",
    "                    target_column=\"production\",\n",
    "                    date_column=\"effectivedate\",\n",
    "                    comparison_columns = comp_cols,\n",
    "                    models_to_run=models_to_run,\n",
    "                    optimization_metric=opt,   # or 'mae'\n",
    "                    train_window_days=180,\n",
    "                    test_window_days=15,\n",
    "                    rows_per_day=24,               \n",
    "                    max_iterations = 2,\n",
    "                    barplot_filename=f\"forecast_barplot_{opt}_{case_name}_plant{plant}_idx{starter}.html\",\n",
    "                    lineplot_filename=f\"forecast_lineplot_{opt}_{case_name}_plant{plant}_idx{starter}.html\",\n",
    "                    max_clip=150,\n",
    "                    start_idx=starter\n",
    "                )\n",
    "                # Optionally, save the predictions DataFrame\n",
    "                predictions.to_csv(f\"forecast_predictions_{opt}_{case_name}_plant{plant}_idx{starter}.csv\", index=False)\n",
    "                print(\"Forecasting pipeline completed. Metrics:\")\n",
    "                print(metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194ef0cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_case = df_c4.copy()\n",
    "df_case = df_case[df_case.plant_name == 1].drop(columns=[\"plant_name\", \"capacity\"])\n",
    "\n",
    "# Assume target is \"production\" and date is \"effectivedate\"\n",
    "\n",
    "# Define which models to run – choose any subset of:\n",
    "# 'arima', 'prophet', 'prophet_reg', 'lgbm', 'xgboost', 'catboost'\n",
    "models_to_run = ['baseline_yesterday', 'baseline_mean7', 'baseline_last','arima', \"sarima\", 'prophet', 'prophet_reg', 'lgbm', 'xgboost', 'catboost','weighted_ensemble']\n",
    "# models_to_run = [\"sarima\"]\n",
    "# Run the forecasting pipeline.\n",
    "predictions, metrics = run_forecasting_pipeline(\n",
    "    df=df_case,\n",
    "    target_column=\"production\",\n",
    "    date_column=\"effectivedate\",\n",
    "    comparison_columns = [\"provider1_fc1200\",\"provider2_fc1200\"],\n",
    "    models_to_run=models_to_run,\n",
    "    optimization_metric='mae',   # or 'mae'\n",
    "    train_window_days=30,\n",
    "    test_window_days=7,\n",
    "    rows_per_day=24,               \n",
    "    max_iterations = 1,\n",
    "    barplot_filename=\"forecast_barplota.html\",\n",
    "    lineplot_filename=\"forecast_lineplot.html\",\n",
    "    max_clip=23.3\n",
    ")\n",
    "\n",
    "# Optionally, save the predictions DataFrame\n",
    "predictions.to_csv(\"forecast_predictions.csv\", index=False)\n",
    "print(\"Forecasting pipeline completed. Metrics:\")\n",
    "print(metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
